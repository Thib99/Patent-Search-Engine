{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_reciprocal_fusion(scores_dataset, nonciting_dataset_final, top_k=100):\n",
    "    mapping = nonciting_dataset_final.to_dict()\n",
    "\n",
    "    def process_row(row, top_k):\n",
    "        scores = np.array(row[\"scores\"])\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "        selected_scores = []\n",
    "        selected_refs = []\n",
    "        seen = set()\n",
    "        for idx in sorted_indices:\n",
    "            nonciting_app = mapping[\"app_nb\"][idx]\n",
    "            nonciting_pid = mapping[\"pid\"][idx]\n",
    "            if nonciting_app not in seen:\n",
    "                seen.add(nonciting_app)\n",
    "                selected_scores.append(float(scores[idx]))\n",
    "                selected_refs.append((nonciting_app, nonciting_pid))\n",
    "                if len(seen) >= top_k:\n",
    "                    break\n",
    "        return {\n",
    "            \"app_nb\": row[\"app_nb\"],\n",
    "            \"cid\": row[\"cid\"],\n",
    "            \"scores\": selected_scores,\n",
    "            \"app_nb_pids\": selected_refs\n",
    "        }\n",
    "\n",
    "    intermediate = [process_row(row, top_k) for row in scores_dataset]\n",
    "\n",
    "    grouped = {}\n",
    "    for item in intermediate:\n",
    "        key = item[\"app_nb\"]\n",
    "        if key not in grouped:\n",
    "            grouped[key] = {\"scores\": [], \"app_nb_pids\": []}\n",
    "        grouped[key][\"scores\"].extend(item[\"scores\"])\n",
    "        grouped[key][\"app_nb_pids\"].extend(item[\"app_nb_pids\"])\n",
    "\n",
    "    final_results = []\n",
    "    for app_nb, data in grouped.items():\n",
    "        scores_arr = np.array(data[\"scores\"])\n",
    "        refs_list = data[\"app_nb_pids\"]\n",
    "        sorted_indices = np.argsort(scores_arr)[::-1]\n",
    "        final_scores = []\n",
    "        final_refs = []\n",
    "        seen = set()\n",
    "        for idx in sorted_indices:\n",
    "            ref = refs_list[idx]\n",
    "            nonciting_app = ref[0]\n",
    "            if nonciting_app not in seen:\n",
    "                seen.add(nonciting_app)\n",
    "                final_scores.append(float(scores_arr[idx]))\n",
    "                final_refs.append(ref)\n",
    "                if len(seen) >= top_k:\n",
    "                    break\n",
    "        final_results.append({\n",
    "            \"app_nb\": app_nb,\n",
    "            \"scores\": final_scores,\n",
    "            \"app_nb_pids\": final_refs\n",
    "        })\n",
    "\n",
    "    final_dataset = Dataset.from_dict({\n",
    "        \"app_nb\": [item[\"app_nb\"] for item in final_results],\n",
    "        \"scores\": [item[\"scores\"] for item in final_results],\n",
    "        \"app_nb_pids\": [item[\"app_nb_pids\"] for item in final_results]\n",
    "    })\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'App_id': 1, 'C_id': 1, 'score': [0.8046175876531323, 0.2897818882716302, 0.6603585133224931, 0.6339006015754431, 0.25650514822618453, 0.6934534622562989, 0.26959062444750237, 0.6352896450193604, 0.09428964944210427, 0.8192085941643029, 0.7564292298740162, 0.8951369504852561, 0.8103358915938108, 0.1615606804524834, 0.3929402316366044, 0.19627159371238834, 0.644846348701757, 0.7183061891457795, 0.9313179686353118, 0.11934739054135857, 0.3137957357864616, 0.012919090273134759, 0.9776939837646355, 0.12256883849994549, 0.3933584320486342, 0.8958751208365785, 0.5158328127033892, 0.9270546883019697, 0.5248901267526327, 0.3626724984589198, 0.9294980881165552, 0.1697552951243585, 0.9696857543231372, 0.9987690894765648, 0.3580324892371274, 0.5447961250207499, 0.5725959723156058, 0.09182497268786805, 0.9390434533982911, 0.5913630378842478, 0.11836373476686812, 0.7982467451231645, 0.8983464722036612, 0.6644076229358331, 0.03185714399132, 0.26711300629633594, 0.3843858081289959, 0.22547751090679646, 0.8046518746006378, 0.38528353882483346], 'index_ref': [23, 31, 10, 26, 8, 18, 17, 4, 29, 49, 30, 40, 12, 39, 27, 43, 34, 46, 15, 20, 14, 3, 25, 44, 2, 36, 47, 13, 1, 41, 33, 19, 37, 16, 7, 28, 6, 42, 11, 21, 32, 0, 22, 35, 48, 24, 9, 45, 5, 38]}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Paramètres pour la génération des données\n",
    "num_app_ids = 10  # Nombre d'App_id différents\n",
    "num_c_ids_per_app = 5  # Nombre de C_id par App_id\n",
    "num_scores_per_c_id = 50  # Nombre de scores par C_id\n",
    "\n",
    "# Générer des données\n",
    "data = {\n",
    "    'App_id': [],\n",
    "    'C_id': [],\n",
    "    'score': [],\n",
    "    'index_ref': []\n",
    "}\n",
    "\n",
    "for app_id in range(1, num_app_ids + 1):\n",
    "    for c_id in range(1, num_c_ids_per_app + 1):\n",
    "        # Générer des scores aléatoires\n",
    "        scores = np.array([random.uniform(0.0, 1.0) for _ in range(num_scores_per_c_id)])\n",
    "        # Générer des indices de référence aléatoires\n",
    "        index_ref = np.array(range(num_scores_per_c_id))\n",
    "        random.shuffle(index_ref)\n",
    "\n",
    "        # Ajouter les données\n",
    "        data['App_id'].append(app_id)\n",
    "        data['C_id'].append(c_id)\n",
    "        data['score'].append(scores)\n",
    "        data['index_ref'].append(index_ref)\n",
    "\n",
    "# Convertir en un format de dataset\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "\n",
    "out = aggregate_reciprocal_fusion(dataset, dataset, top_k=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
